{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('Dataset/clean_data.csv',index_col='customerID')\n",
    "churn = full_data['Churn'].copy()\n",
    "full_data = full_data.drop('Churn',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, OPTICS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data for training and testing with 80% for training and 20% testing\n",
    "#Uses our preselected random seed to results are reproducible \n",
    "raw_x_train, raw_x_test, y_train, y_test = train_test_split(\n",
    "    full_data,\n",
    "    churn,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import PipelineFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PipelineFactory.create_pipe() missing 1 required keyword-only argument: 'intrnt_sub_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\MLProjects\\TelecomChurnAnalysis\\Model.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MLProjects/TelecomChurnAnalysis/Model.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pf \u001b[39m=\u001b[39m PipelineFactory(raw_x_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MLProjects/TelecomChurnAnalysis/Model.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m log_pipe \u001b[39m=\u001b[39m pf\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MLProjects/TelecomChurnAnalysis/Model.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     engineer\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, random_seed \u001b[39m=\u001b[39;49m RANDOM_SEED, normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MLProjects/TelecomChurnAnalysis/Model.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: PipelineFactory.create_pipe() missing 1 required keyword-only argument: 'intrnt_sub_list'"
     ]
    }
   ],
   "source": [
    "pf = PipelineFactory(raw_x_train)\n",
    "log_pipe = pf.create_pipe(\n",
    "    engineer=False, random_seed = RANDOM_SEED, normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train = norm_pipe.fit_transform(raw_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5634, 27)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use several different algorithms then compare their performance afterwards to determine which is the best to use. The algorithm we will use are: \n",
    "- Logistic Regression\n",
    "- K Nearest Neighbor Classifier\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "Since the implementations selected for the above algorithms have differing aptitudes for missing values and normalization, we will need different preprocessing pipelines of the data. For example, XGBoost and LightGBM can handle nan values (XGBoost learns whether to split nan values during training, while LightGBM allocates nan values to reduce loss afterwards) while the sklearn implementations of Logisitic regression, KNN classifier, and random forest cannot. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('telecomChurn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fbdce887e3e5f960b74eaae67cd2ebc9c84860334727f842ebfba4f686e38cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
